{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6594bcec",
   "metadata": {},
   "source": [
    "# Speech Emotion Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1472a2",
   "metadata": {},
   "source": [
    "Voice often reflects underlying emotion through tone and pitch. Based on this fact, Speech Emotion Recognition (SER) has been developed, which is the act of attempting to recognize human emotion and affective states from speech. As such, in this python project I have tried building a model which will be able to recognize emotion from sound files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d5fd6c",
   "metadata": {},
   "source": [
    "### Installing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a040a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in ./opt/anaconda3/lib/python3.8/site-packages (0.8.1)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in ./opt/anaconda3/lib/python3.8/site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: pooch>=1.0 in ./opt/anaconda3/lib/python3.8/site-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from librosa) (5.0.6)\n",
      "Requirement already satisfied: resampy>=0.2.2 in ./opt/anaconda3/lib/python3.8/site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from librosa) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./opt/anaconda3/lib/python3.8/site-packages (from librosa) (1.20.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./opt/anaconda3/lib/python3.8/site-packages (from librosa) (20.9)\n",
      "Requirement already satisfied: audioread>=2.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in ./opt/anaconda3/lib/python3.8/site-packages (from librosa) (0.24.1)\n",
      "Requirement already satisfied: joblib>=0.14 in ./opt/anaconda3/lib/python3.8/site-packages (from librosa) (1.0.1)\n",
      "Requirement already satisfied: numba>=0.43.0 in ./opt/anaconda3/lib/python3.8/site-packages (from librosa) (0.53.1)\n",
      "Requirement already satisfied: setuptools in ./opt/anaconda3/lib/python3.8/site-packages (from numba>=0.43.0->librosa) (52.0.0.post20210125)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in ./opt/anaconda3/lib/python3.8/site-packages (from numba>=0.43.0->librosa) (0.36.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->librosa) (2.4.7)\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/lib/python3.8/site-packages (from pooch>=1.0->librosa) (2.25.1)\n",
      "Requirement already satisfied: appdirs in ./opt/anaconda3/lib/python3.8/site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: six>=1.3 in ./opt/anaconda3/lib/python3.8/site-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in ./opt/anaconda3/lib/python3.8/site-packages (from soundfile>=0.10.2->librosa) (1.14.5)\n",
      "Requirement already satisfied: pycparser in ./opt/anaconda3/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fb7d638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in ./opt/anaconda3/lib/python3.8/site-packages (0.2.11)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c414c62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in ./opt/anaconda3/lib/python3.8/site-packages (0.10.3.post1)\r\n",
      "Requirement already satisfied: cffi>=1.0 in ./opt/anaconda3/lib/python3.8/site-packages (from soundfile) (1.14.5)\r\n",
      "Requirement already satisfied: pycparser in ./opt/anaconda3/lib/python3.8/site-packages (from cffi>=1.0->soundfile) (2.20)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cff0f41",
   "metadata": {},
   "source": [
    "### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f1e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690acd73",
   "metadata": {},
   "source": [
    "### Extracting features from a sound file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f649b508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ab940",
   "metadata": {},
   "source": [
    "### Given and required emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e50b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotions in the RAVDESS dataset\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "\n",
    "# Emotions to observe\n",
    "observed_emotions=['calm', 'happy', 'fearful', 'disgust']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56ccc8e",
   "metadata": {},
   "source": [
    "### Loading the dataset and extracting features for each sound file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47b6d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob(\"/Users/anweashasaha/Downloads/speech-emotion-recognition-ravdess-data/Actor_*/*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47657633",
   "metadata": {},
   "source": [
    "### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d637d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=load_data(test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0471e11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 192)\n"
     ]
    }
   ],
   "source": [
    "print((x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75edab15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted: 180\n"
     ]
    }
   ],
   "source": [
    "print(f'Features extracted: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f66426b",
   "metadata": {},
   "source": [
    "### Initializing the Multi Layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5538e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a80d8b",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2363afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
       "              learning_rate='adaptive', max_iter=500)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7d31ab",
   "metadata": {},
   "source": [
    "### Predicting for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87e7c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeddefe",
   "metadata": {},
   "source": [
    "### Calculating the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddc03532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6414a5fa",
   "metadata": {},
   "source": [
    "We obtain an accuracy of 75% from this model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
